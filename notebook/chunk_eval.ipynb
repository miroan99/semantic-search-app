{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T11:12:18.899122Z",
     "start_time": "2025-11-14T11:12:18.894869Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from app.utils import chunk_text\n",
    "ROOT = Path(r\"C:\\Users\\micha\\PythonProjects\\semantic-search-app\")\n",
    "RAW = ROOT / \"data\" / \"raw_docs\"\n",
    "path = RAW / \"archimedes.txt\"\n",
    "text = path.read_text(encoding=\"utf-8\")\n",
    "chunks = chunk_text(text, 300, 100)\n",
    "print(len(chunks))\n",
    "for c in chunks[:3]:\n",
    "    print(len(c), c[:300])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "300 In order to enable the reader to arrive at a correct understanding of\n",
      "the place of Archimedes and of the significance of his work it is\n",
      "necessary to pass in review the course of development of Greek geometry\n",
      "from its first beginnings down to the time of Euclid and Archimedes.\n",
      "\n",
      "Greek authors from Her\n",
      "300 eometry\n",
      "from its first beginnings down to the time of Euclid and Archimedes.\n",
      "\n",
      "Greek authors from Herodotus downwards agree in saying that geometry was\n",
      "invented by the Egyptians and that it came into Greece from Egypt. One\n",
      "account says:--\n",
      "\n",
      "\"Geometry is said by many to have been invented among the Egy\n",
      "300 reece from Egypt. One\n",
      "account says:--\n",
      "\n",
      "\"Geometry is said by many to have been invented among the Egyptians, its\n",
      "origin being due to the measurement of plots of land. This was necessary\n",
      "there because of the rising of the Nile, which obliterated the\n",
      "boundaries appertaining to separate owners. Nor is i\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:14:54.378596Z",
     "start_time": "2025-11-14T11:14:54.232228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from app.utils import embed_text\n",
    "vec1 = embed_text(\"dog\").shape\n",
    "vec2 = embed_text(\"car\").shape\n",
    "print(vec1, vec2)\n"
   ],
   "id": "e3f97c989f46be36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384) (1, 384)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:16:53.865422Z",
     "start_time": "2025-11-14T11:16:53.851357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from app.utils import load_faiss_index\n",
    "index, chunks = load_faiss_index()\n",
    "print(index.d)    # should equal embedding size\n"
   ],
   "id": "351b58212f0a5b40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T16:04:24.399787Z",
     "start_time": "2025-11-14T16:04:24.386253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from app.utils import load_faiss_index, embed_text\n",
    "\n",
    "def test_query(q):\n",
    "    index, chunks = load_faiss_index()\n",
    "\n",
    "    q_vec = embed_text(q).reshape(1, -1)\n",
    "    D, I = index.search(q_vec, 5)\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        print(score, chunks[idx].get(\"text\", \"\")[:120])\n",
    "\n",
    "test_query(\"paralyze\")"
   ],
   "id": "1d0fcfa27eded4ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30942202 order to force down and under the bore of soft snow that surged like a wave before it. On the sled, securely lashed, was\n",
      "0.25996855 hing at the futility of life and the effort of life. It was the Wild, the savage, frozen-hearted Northland Wild. But the\n",
      "0.25151676 essor of gymnastics, so as to make better use of my talents; and then I was a sergeant fireman at Paris, and assisted at\n",
      "0.22414215 hazardous than to continue across the plateau, so, putting spurs to my poor beast, I made a dash for the opening to the \n",
      "0.21865231 ly to prop his moccasins before the fire. “An’ I wisht this cold snap’d break,” he went on. “It’s ben fifty below for tw\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T16:12:44.487581Z",
     "start_time": "2025-11-14T16:12:44.482418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "list(ROOT.glob(\"*.ipynb\"))\n"
   ],
   "id": "c6c04da9a209c61f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/micha/PythonProjects/semantic-search-app/notebook/chunk_eval.ipynb'),\n",
       " WindowsPath('C:/Users/micha/PythonProjects/semantic-search-app/notebook/test_chunks.ipynb')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Day 9 — Chunk Evaluation\n",
    "\n",
    "## Vericer att skrivet tekst er korrekt chunket\n",
    "\n",
    "### test chunks datatypen\n",
    "\n",
    "- Tjek chunk længder\n",
    "- Tjek overlap\n",
    "- Kør `test_query()` på et par søgeord\n",
    "\n",
    "'''\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "list(ROOT.glob(\"*.ipynb\"))\n",
    "\n",
    "'''"
   ],
   "id": "e5d01462f3648cd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def rag_answer(query: str) -> str:\n",
    "    index, chunks = load_faiss_index()\n",
    "    q_vec = embed_text(query).reshape(1, -1)\n",
    "\n",
    "    D, I = index.search(q_vec, 5)\n",
    "    context = \"\\n\".join(chunks[i][\"text\"] for i in I)\n",
    "\n",
    "    answer = call_model(context, query)\n",
    "    return answer\n"
   ],
   "id": "a31190a9f3221d08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
